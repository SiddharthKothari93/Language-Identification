{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL Project - CRNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux5dR2eHbcCI",
        "colab_type": "code",
        "outputId": "ac880a1e-05ff-4451-f3e5-4a2fa4c53308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow  as tf\n",
        "from tensorflow.contrib.layers import fully_connected\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import pandas as pd\n",
        "import librosa\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import glob\n",
        "import pickle\n",
        "from statistics import mean\n",
        "import keras\n",
        "from keras.layers.core import Dense, Permute, Reshape\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.regularizers import l2\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n",
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFbV0cO0bl1V",
        "colab_type": "code",
        "outputId": "f1ddb284-062e-4201-a97d-084e8868369a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "drive.mount('/content/Drive/',force_remount =  True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/Drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDMCPAx4bsTE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dirpath = \"/content/Drive/My Drive/DL project/New Files/Final Data/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMj-dbnIb_m0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading training pickle files\n",
        "sound_lists_pkl_in = open(dirpath+\"ca_data_padded_tr.pkl\", \"rb\")\n",
        "ca_data_tr = pickle.load(sound_lists_pkl_in)\n",
        "\n",
        "sound_lists_pkl_in = open(dirpath+\"en_data_padded_tr.pkl\", \"rb\")\n",
        "en_data_tr = pickle.load(sound_lists_pkl_in)\n",
        "\n",
        "sound_lists_pkl_in = open(dirpath+\"fr_data_padded_tr.pkl\", \"rb\")\n",
        "fr_data_tr = pickle.load(sound_lists_pkl_in)\n",
        "\n",
        "sound_lists_pkl_in = open(dirpath+\"it_data_padded_tr.pkl\", \"rb\")\n",
        "it_data_tr = pickle.load(sound_lists_pkl_in)\n",
        "\n",
        "sound_lists_pkl_in = open(dirpath+\"de_data_padded_tr.pkl\", \"rb\")\n",
        "de_data_tr = pickle.load(sound_lists_pkl_in)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxHG9-wHcmfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading test pickle files\n",
        "sound_lists_pkl_in = open(dirpath+\"ca_data_padded_te.pkl\", \"rb\")\n",
        "ca_data_te = pickle.load(sound_lists_pkl_in)\n",
        "\n",
        "sound_lists_pkl_in = open(dirpath+\"en_data_padded_te.pkl\", \"rb\")\n",
        "en_data_te = pickle.load(sound_lists_pkl_in)\n",
        "\n",
        "sound_lists_pkl_in = open(dirpath+\"fr_data_padded_te.pkl\", \"rb\")\n",
        "fr_data_te = pickle.load(sound_lists_pkl_in)\n",
        "\n",
        "sound_lists_pkl_in = open(dirpath+\"it_data_padded_te.pkl\", \"rb\")\n",
        "it_data_te = pickle.load(sound_lists_pkl_in)\n",
        "\n",
        "sound_lists_pkl_in = open(dirpath+\"de_data_padded_te.pkl\", \"rb\")\n",
        "de_data_te = pickle.load(sound_lists_pkl_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTewX5BTcsHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_data_tr = np.concatenate((ca_data_tr, en_data_tr, fr_data_tr, it_data_tr, de_data_tr), axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYe44TBTczm3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_data_te = np.concatenate((ca_data_te, en_data_te, fr_data_te, it_data_te, de_data_te), axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62U6KWn3dS_5",
        "colab_type": "code",
        "outputId": "0b453274-dee6-4561-85ca-9c77b1ea3916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(final_data_tr.shape)\n",
        "print(final_data_te.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 2)\n",
            "(2500, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBvPb6rDfZ_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del(de_data_te)\n",
        "del(ca_data_te)\n",
        "del(en_data_te)\n",
        "del(fr_data_te)\n",
        "del(it_data_te)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2g5oMzjflYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del(de_data_tr)\n",
        "del(ca_data_tr)\n",
        "del(en_data_tr)\n",
        "del(fr_data_tr)\n",
        "del(it_data_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEb3rX0psnMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# final_data_tr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRt82WVGs4iG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.shuffle(final_data_tr)\n",
        "np.random.shuffle(final_data_te)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8YcG4vts72w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_padded_pkl = open(dirpath+\"final_data_tr.pkl\", \"wb\")\n",
        "# pickle.dump(final_data_tr, data_padded_pkl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MgEkHEwuuAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data_padded_pkl = open(dirpath+\"final_data_te.pkl\", \"wb\")\n",
        "# pickle.dump(final_data_te, data_padded_pkl)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbJOywlP8j1w",
        "colab_type": "text"
      },
      "source": [
        "### Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qZ31OCn8ll5",
        "colab_type": "code",
        "outputId": "9e019973-4792-432b-e3e5-24a92975ebf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\n",
        "labels_tr =[]\n",
        "for i in range(len(final_data_tr)):\n",
        "\n",
        "      labels_tr.append(final_data_tr[i][1])  \n",
        "\n",
        "labels_tr = np.array(labels_tr)\n",
        "labels_tr\n",
        "\n",
        "classnames, indices = np.unique(labels_tr, return_inverse=True)\n",
        "print(indices)\n",
        "\n",
        "final_labels_tr = indices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 2 0 ... 2 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyrKk9g68lEh",
        "colab_type": "code",
        "outputId": "04cb435b-830c-4e06-dd2f-1b83d70e8993",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "labels_te =[]\n",
        "for i in range(len(final_data_te)):\n",
        "\n",
        "      labels_te.append(final_data_te[i][1])  \n",
        "\n",
        "labels_te = np.array(labels_te)\n",
        "labels_te\n",
        "\n",
        "classnames, indices = np.unique(labels_te, return_inverse=True)\n",
        "print(indices)\n",
        "\n",
        "final_labels_te = indices"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 2 1 ... 1 3 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jALa80G-fkc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvB12R0l_TO3",
        "colab_type": "code",
        "outputId": "3c28eb97-ede6-49b2-821c-5be50b8333b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "final_X_tr =[]\n",
        "for i in range(len(final_data_tr)):\n",
        "\n",
        "      final_X_tr.append(final_data_tr[i][0])  \n",
        "\n",
        "final_X_tr = np.array(final_X_tr)\n",
        "final_X_tr[0].shape\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(972, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQOkHS85_wa2",
        "colab_type": "code",
        "outputId": "47ea724a-27f4-4757-c776-6ef0e35715f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "final_X_te =[]\n",
        "for i in range(len(final_data_te)):\n",
        "\n",
        "      final_X_te.append(final_data_te[i][0])  \n",
        "\n",
        "final_X_te = np.array(final_X_te)\n",
        "final_X_te[0].shape\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(972, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7khvS8a8Wg1",
        "colab_type": "text"
      },
      "source": [
        "### Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fH90G2JyxCtE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers.core import Dense, Permute, Reshape, Flatten \n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.wrappers import Bidirectional\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers import Dropout, TimeDistributed\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYoOypuT8ZCU",
        "colab_type": "code",
        "outputId": "c2f404b0-9b44-4863-fd2e-1c20895d433f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "model = Sequential()\n",
        "weight_decay = 0.001\n",
        "\n",
        "model.add(Convolution2D(32, kernel_size=(4,4), strides=(1,1), activation=\"relu\", padding=\"same\", kernel_regularizer=l2(weight_decay), input_shape=(972,40,1)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(64, kernel_size=(4,4), strides=(1,1), activation=\"relu\", kernel_regularizer=l2(weight_decay), padding=\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Convolution2D(128, kernel_size=(4,4), strides=(1,1), activation=\"relu\", kernel_regularizer=l2(weight_decay), padding=\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(256, kernel_size=(4,4), strides=(1,1), activation=\"relu\", kernel_regularizer=l2(weight_decay), padding=\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"))\n",
        "\n",
        "model.add(Convolution2D(512, kernel_size=(4,4), strides=(1,1), activation=\"relu\", kernel_regularizer=l2(weight_decay), padding=\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"))\n",
        "\n",
        "\n",
        "model.add(Convolution2D(512, kernel_size=(4,4), strides=(1,1), activation=\"relu\", kernel_regularizer=l2(weight_decay), padding=\"same\"))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding=\"same\"))\n",
        "\n",
        "print(model.layers[-1].output_shape)\n",
        "\n",
        "#model.add(Permute((2,1,3)))\n",
        "\n",
        "print(model.layers[-1].output_shape)\n",
        "\n",
        "bs, x, y, c = model.layers[-1].output_shape\n",
        "\n",
        "model.add(Reshape([x,y*c]))\n",
        "\n",
        "print(model.layers[-1].output_shape)\n",
        "\n",
        "#model.add(LSTM(256, activation=\"tanh\", return_sequences=True))\n",
        "\n",
        "model.add(LSTM(512, activation=\"relu\",dropout = 0.7, return_sequences=False))\n",
        "\n",
        "# model.add(Flatten())\n",
        "\n",
        "# model.add(Dense(256, activation=\"relu\"))\n",
        "\n",
        "# model.add(Dropout(rate=0.7))\n",
        "\n",
        "model.add(Dense(5, activation=\"softmax\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 16, 1, 512)\n",
            "(None, 16, 1, 512)\n",
            "(None, 16, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr5bUTx5vk3-",
        "colab_type": "code",
        "outputId": "05b0a498-05a2-4fe9-ea39-0109c8eab218",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_71 (Conv2D)           (None, 972, 40, 32)       544       \n",
            "_________________________________________________________________\n",
            "batch_normalization_71 (Batc (None, 972, 40, 32)       128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_71 (MaxPooling (None, 486, 20, 32)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_72 (Conv2D)           (None, 486, 20, 64)       32832     \n",
            "_________________________________________________________________\n",
            "batch_normalization_72 (Batc (None, 486, 20, 64)       256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_72 (MaxPooling (None, 243, 10, 64)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_73 (Conv2D)           (None, 243, 10, 128)      131200    \n",
            "_________________________________________________________________\n",
            "batch_normalization_73 (Batc (None, 243, 10, 128)      512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_73 (MaxPooling (None, 122, 5, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_74 (Conv2D)           (None, 122, 5, 256)       524544    \n",
            "_________________________________________________________________\n",
            "batch_normalization_74 (Batc (None, 122, 5, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_74 (MaxPooling (None, 61, 3, 256)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_75 (Conv2D)           (None, 61, 3, 512)        2097664   \n",
            "_________________________________________________________________\n",
            "batch_normalization_75 (Batc (None, 61, 3, 512)        2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_75 (MaxPooling (None, 31, 2, 512)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_76 (Conv2D)           (None, 31, 2, 512)        4194816   \n",
            "_________________________________________________________________\n",
            "batch_normalization_76 (Batc (None, 31, 2, 512)        2048      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_76 (MaxPooling (None, 16, 1, 512)        0         \n",
            "_________________________________________________________________\n",
            "reshape_18 (Reshape)         (None, 16, 512)           0         \n",
            "_________________________________________________________________\n",
            "lstm_24 (LSTM)               (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 5)                 2565      \n",
            "=================================================================\n",
            "Total params: 9,089,381\n",
            "Trainable params: 9,086,373\n",
            "Non-trainable params: 3,008\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDmsk8mu5kel",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = Sequential()\n",
        "# weight_decay = 0.001\n",
        "# model.add(Convolution2D(64, 2, strides = 1, padding='same',W_regularizer=l2(weight_decay), activation=\"relu\", input_shape=(972,40,1)))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D(pool_size=(10,5), strides=(2, 2)))\n",
        "\n",
        "# print(model.layers[-1].output_shape)\n",
        "\n",
        "# model.add(Convolution2D(128, 2,  strides = 1, padding='same', W_regularizer=l2(weight_decay), activation=\"relu\"))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D(pool_size=(10,5), strides=(2, 2)))\n",
        "\n",
        "# print(model.layers[-1].output_shape)\n",
        "\n",
        "# model.add(Convolution2D(256, 2,  strides = 1, padding='same', W_regularizer=l2(weight_decay), activation=\"relu\"))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D(pool_size=(10,2), strides=(2, 2)))\n",
        "\n",
        "# print(model.layers[-1].output_shape)\n",
        "\n",
        "# model.add(Convolution2D(256, 2,  strides = 1, padding='same', W_regularizer=l2(weight_decay), activation=\"relu\"))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(MaxPooling2D(pool_size=(10,2), strides=(2, 2)))\n",
        "\n",
        "# print(model.layers[-1].output_shape)\n",
        "\n",
        "# # model.add(Convolution2D(512, 2,  strides = 1, padding='same', W_regularizer=l2(weight_decay), activation=\"relu\"))\n",
        "# # model.add(BatchNormalization())\n",
        "# # model.add(MaxPooling2D(pool_size=(10,2), strides=(2, 2)))\n",
        "\n",
        "# # print(model.layers[-1].output_shape)\n",
        "\n",
        "# # model.add(Convolution2D(512, 2,  strides = 1, padding='same', W_regularizer=l2(weight_decay), activation=\"relu\"))\n",
        "# # model.add(BatchNormalization())\n",
        "# # model.add(MaxPooling2D(pool_size=(10,2), strides=(2, 2)))\n",
        "\n",
        "# # print(model.layers[-1].output_shape)\n",
        "\n",
        "# # model.add(Convolution2D(512, (10,2), 1, W_regularizer=l2(weight_decay), activation=\"relu\"))\n",
        "# # model.add(BatchNormalization())\n",
        "# # model.add(MaxPooling2D(pool_size=(10,2), strides=(2, 2)))\n",
        "\n",
        "# # (bs, y, x, c) --> (bs, x, y, c)\n",
        "\n",
        "# bs, x, y, c = model.layers[-1].output_shape\n",
        "# model.add(Reshape((x, y*c)))\n",
        "\n",
        "# model.add(Bidirectional(LSTM(256, return_sequences=False), merge_mode=\"concat\"))\n",
        "# model.add(Dense(5, activation=\"softmax\"))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvbPfFuCAFlR",
        "colab_type": "code",
        "outputId": "075dfa65-2102-4a86-97ab-ede40c06c6fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        }
      },
      "source": [
        "del(final_data_tr)\n",
        "del(final_data_te)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-9c5e2bda8800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_data_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_data_te\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'final_data_tr' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBTHNw0qAgdP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tx = np.array(final_X_tr[:8000])\n",
        "cvx = np.array(final_X_tr[8000:])\n",
        "ty = np.array(final_labels_tr[:8000])\n",
        "cvy = np.array(final_labels_tr[8000:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPa_Hz2yBNxt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del(final_labels_tr)\n",
        "del(final_X_tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-YaBGQcBUln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cvy = to_categorical(cvy)\n",
        "ty = to_categorical(ty)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVhlJEtUCeh4",
        "colab_type": "code",
        "outputId": "bc105c3e-e3be-4a3c-cc66-0ea106526716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "ty"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6IcH27SAixd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "             optimizer=keras.optimizers.adam(lr=0.0002),\n",
        "             metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDHTkxA-BugR",
        "colab_type": "code",
        "outputId": "fbeaa958-2238-4565-a763-a80816cf44cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3925
        }
      },
      "source": [
        "model.fit(tx.reshape(-1,972,40,1), ty,\n",
        "          batch_size=300,\n",
        "          epochs=150,\n",
        "          verbose=1,\n",
        "          validation_data=(cvx.reshape(-1,972,40,1),cvy)\n",
        "         )\n",
        "          "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 8000 samples, validate on 2000 samples\n",
            "Epoch 1/150\n",
            "8000/8000 [==============================] - 50s 6ms/step - loss: 2.7217 - acc: 0.3967 - val_loss: 2.2547 - val_acc: 0.5225\n",
            "Epoch 2/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 2.1181 - acc: 0.5423 - val_loss: 1.9594 - val_acc: 0.6125\n",
            "Epoch 3/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.9386 - acc: 0.6085 - val_loss: 1.8529 - val_acc: 0.6335\n",
            "Epoch 4/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.8319 - acc: 0.6515 - val_loss: 1.7270 - val_acc: 0.7255\n",
            "Epoch 5/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.7674 - acc: 0.6744 - val_loss: 1.6737 - val_acc: 0.7420\n",
            "Epoch 6/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.6836 - acc: 0.7088 - val_loss: 2.2373 - val_acc: 0.4930\n",
            "Epoch 7/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.6260 - acc: 0.7295 - val_loss: 1.7249 - val_acc: 0.6860\n",
            "Epoch 8/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.5610 - acc: 0.7481 - val_loss: 2.1484 - val_acc: 0.5425\n",
            "Epoch 9/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.4771 - acc: 0.7824 - val_loss: 1.5579 - val_acc: 0.7755\n",
            "Epoch 10/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.4134 - acc: 0.8049 - val_loss: 1.8946 - val_acc: 0.6330\n",
            "Epoch 11/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.3239 - acc: 0.8369 - val_loss: 1.7517 - val_acc: 0.6970\n",
            "Epoch 12/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.2799 - acc: 0.8569 - val_loss: 1.9529 - val_acc: 0.6375\n",
            "Epoch 13/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.2133 - acc: 0.8725 - val_loss: 1.9886 - val_acc: 0.6065\n",
            "Epoch 14/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.1520 - acc: 0.8911 - val_loss: 1.9148 - val_acc: 0.6340\n",
            "Epoch 15/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.0715 - acc: 0.9194 - val_loss: 2.5356 - val_acc: 0.5460\n",
            "Epoch 16/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.0359 - acc: 0.9265 - val_loss: 1.5437 - val_acc: 0.7730\n",
            "Epoch 17/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.9853 - acc: 0.9422 - val_loss: 2.0932 - val_acc: 0.6680\n",
            "Epoch 18/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 1.0322 - acc: 0.9243 - val_loss: 1.6304 - val_acc: 0.7540\n",
            "Epoch 19/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.9104 - acc: 0.9605 - val_loss: 2.3853 - val_acc: 0.7010\n",
            "Epoch 20/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.8736 - acc: 0.9680 - val_loss: 1.4236 - val_acc: 0.8260\n",
            "Epoch 21/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.8577 - acc: 0.9693 - val_loss: 1.9442 - val_acc: 0.7145\n",
            "Epoch 22/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.8221 - acc: 0.9798 - val_loss: 1.9708 - val_acc: 0.7535\n",
            "Epoch 23/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.7996 - acc: 0.9801 - val_loss: 1.4889 - val_acc: 0.8380\n",
            "Epoch 24/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.7858 - acc: 0.9826 - val_loss: 1.7149 - val_acc: 0.7810\n",
            "Epoch 25/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.7609 - acc: 0.9859 - val_loss: 1.5493 - val_acc: 0.8210\n",
            "Epoch 26/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.7541 - acc: 0.9841 - val_loss: 1.4658 - val_acc: 0.8340\n",
            "Epoch 27/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.7552 - acc: 0.9798 - val_loss: 1.4646 - val_acc: 0.8215\n",
            "Epoch 28/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.7233 - acc: 0.9863 - val_loss: 1.8966 - val_acc: 0.7985\n",
            "Epoch 29/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.6973 - acc: 0.9916 - val_loss: 1.4257 - val_acc: 0.8405\n",
            "Epoch 30/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.7048 - acc: 0.9868 - val_loss: 1.4213 - val_acc: 0.8365\n",
            "Epoch 31/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.6833 - acc: 0.9875 - val_loss: 1.6429 - val_acc: 0.8135\n",
            "Epoch 32/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.6751 - acc: 0.9886 - val_loss: 2.4724 - val_acc: 0.7430\n",
            "Epoch 33/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.6775 - acc: 0.9864 - val_loss: 1.7726 - val_acc: 0.8200\n",
            "Epoch 34/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.6698 - acc: 0.9853 - val_loss: 1.3588 - val_acc: 0.8455\n",
            "Epoch 35/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.6337 - acc: 0.9934 - val_loss: 1.8114 - val_acc: 0.8170\n",
            "Epoch 36/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.6240 - acc: 0.9931 - val_loss: 1.4462 - val_acc: 0.8495\n",
            "Epoch 37/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.6129 - acc: 0.9925 - val_loss: 3.4217 - val_acc: 0.6355\n",
            "Epoch 38/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.6167 - acc: 0.9880 - val_loss: 1.3753 - val_acc: 0.8570\n",
            "Epoch 39/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.6176 - acc: 0.9855 - val_loss: 2.0125 - val_acc: 0.7555\n",
            "Epoch 40/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.5891 - acc: 0.9911 - val_loss: 1.3874 - val_acc: 0.8315\n",
            "Epoch 41/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.5663 - acc: 0.9953 - val_loss: 1.4461 - val_acc: 0.8165\n",
            "Epoch 42/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.5510 - acc: 0.9981 - val_loss: 4.1968 - val_acc: 0.5720\n",
            "Epoch 43/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.5459 - acc: 0.9955 - val_loss: 1.5940 - val_acc: 0.8350\n",
            "Epoch 44/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.5318 - acc: 0.9974 - val_loss: 1.7183 - val_acc: 0.8315\n",
            "Epoch 45/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.5255 - acc: 0.9954 - val_loss: 1.9949 - val_acc: 0.7990\n",
            "Epoch 46/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.5355 - acc: 0.9896 - val_loss: 1.7505 - val_acc: 0.8215\n",
            "Epoch 47/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.5292 - acc: 0.9901 - val_loss: 1.7082 - val_acc: 0.8070\n",
            "Epoch 48/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.5810 - acc: 0.9708 - val_loss: 2.6876 - val_acc: 0.6460\n",
            "Epoch 49/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.5617 - acc: 0.9775 - val_loss: 1.4169 - val_acc: 0.8205\n",
            "Epoch 50/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.5148 - acc: 0.9934 - val_loss: 1.7764 - val_acc: 0.7950\n",
            "Epoch 51/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4960 - acc: 0.9970 - val_loss: 1.4252 - val_acc: 0.8380\n",
            "Epoch 52/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4955 - acc: 0.9951 - val_loss: 1.5560 - val_acc: 0.8255\n",
            "Epoch 53/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4836 - acc: 0.9956 - val_loss: 1.1728 - val_acc: 0.8670\n",
            "Epoch 54/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4688 - acc: 0.9976 - val_loss: 1.1998 - val_acc: 0.8510\n",
            "Epoch 55/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4623 - acc: 0.9970 - val_loss: 1.1614 - val_acc: 0.8600\n",
            "Epoch 56/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4550 - acc: 0.9970 - val_loss: 1.4821 - val_acc: 0.8195\n",
            "Epoch 57/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4494 - acc: 0.9964 - val_loss: 1.7561 - val_acc: 0.8125\n",
            "Epoch 58/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4454 - acc: 0.9958 - val_loss: 1.3532 - val_acc: 0.8295\n",
            "Epoch 59/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4358 - acc: 0.9956 - val_loss: 1.7037 - val_acc: 0.7655\n",
            "Epoch 60/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4203 - acc: 0.9991 - val_loss: 1.2224 - val_acc: 0.8530\n",
            "Epoch 61/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4132 - acc: 0.9986 - val_loss: 1.5557 - val_acc: 0.8275\n",
            "Epoch 62/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4109 - acc: 0.9971 - val_loss: 1.5825 - val_acc: 0.8175\n",
            "Epoch 63/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4156 - acc: 0.9943 - val_loss: 1.5079 - val_acc: 0.8215\n",
            "Epoch 64/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4081 - acc: 0.9940 - val_loss: 1.4176 - val_acc: 0.7885\n",
            "Epoch 65/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.4007 - acc: 0.9958 - val_loss: 1.5654 - val_acc: 0.8160\n",
            "Epoch 66/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3959 - acc: 0.9941 - val_loss: 1.2575 - val_acc: 0.8490\n",
            "Epoch 67/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3905 - acc: 0.9940 - val_loss: 1.6080 - val_acc: 0.8320\n",
            "Epoch 68/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3800 - acc: 0.9956 - val_loss: 1.6605 - val_acc: 0.7840\n",
            "Epoch 69/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3737 - acc: 0.9964 - val_loss: 1.2351 - val_acc: 0.8550\n",
            "Epoch 70/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3672 - acc: 0.9966 - val_loss: 1.6864 - val_acc: 0.7985\n",
            "Epoch 71/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3623 - acc: 0.9974 - val_loss: 1.8553 - val_acc: 0.7915\n",
            "Epoch 72/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3672 - acc: 0.9946 - val_loss: 1.2401 - val_acc: 0.8555\n",
            "Epoch 73/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3618 - acc: 0.9949 - val_loss: 1.1605 - val_acc: 0.8420\n",
            "Epoch 74/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3505 - acc: 0.9969 - val_loss: 1.2536 - val_acc: 0.8465\n",
            "Epoch 75/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3481 - acc: 0.9950 - val_loss: 1.2602 - val_acc: 0.8445\n",
            "Epoch 76/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3437 - acc: 0.9949 - val_loss: 1.1364 - val_acc: 0.8510\n",
            "Epoch 77/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3464 - acc: 0.9935 - val_loss: 1.3612 - val_acc: 0.8290\n",
            "Epoch 78/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3315 - acc: 0.9968 - val_loss: 1.1593 - val_acc: 0.8555\n",
            "Epoch 79/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3243 - acc: 0.9975 - val_loss: 1.0134 - val_acc: 0.8810\n",
            "Epoch 80/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3155 - acc: 0.9994 - val_loss: 1.6645 - val_acc: 0.7790\n",
            "Epoch 81/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3096 - acc: 0.9990 - val_loss: 0.9760 - val_acc: 0.8820\n",
            "Epoch 82/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3041 - acc: 0.9993 - val_loss: 0.9381 - val_acc: 0.8925\n",
            "Epoch 83/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3003 - acc: 0.9989 - val_loss: 0.9955 - val_acc: 0.8655\n",
            "Epoch 84/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3013 - acc: 0.9974 - val_loss: 1.3376 - val_acc: 0.8220\n",
            "Epoch 85/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.2928 - acc: 0.9988 - val_loss: 1.1908 - val_acc: 0.8720\n",
            "Epoch 86/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.2931 - acc: 0.9974 - val_loss: 1.3991 - val_acc: 0.8345\n",
            "Epoch 87/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.3075 - acc: 0.9924 - val_loss: 1.1796 - val_acc: 0.8385\n",
            "Epoch 88/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.2983 - acc: 0.9941 - val_loss: 1.6360 - val_acc: 0.7645\n",
            "Epoch 89/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.2880 - acc: 0.9961 - val_loss: 1.0192 - val_acc: 0.8595\n",
            "Epoch 90/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.2797 - acc: 0.9974 - val_loss: 1.4618 - val_acc: 0.8370\n",
            "Epoch 91/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.2772 - acc: 0.9975 - val_loss: 1.3975 - val_acc: 0.7985\n",
            "Epoch 92/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.2786 - acc: 0.9966 - val_loss: 1.2326 - val_acc: 0.8425\n",
            "Epoch 93/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.2776 - acc: 0.9949 - val_loss: 1.7416 - val_acc: 0.7655\n",
            "Epoch 94/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.2675 - acc: 0.9973 - val_loss: 1.1540 - val_acc: 0.8355\n",
            "Epoch 95/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.2594 - acc: 0.9985 - val_loss: 1.3700 - val_acc: 0.8265\n",
            "Epoch 96/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.2571 - acc: 0.9989 - val_loss: 1.0675 - val_acc: 0.8715\n",
            "Epoch 97/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.2498 - acc: 0.9995 - val_loss: 0.9584 - val_acc: 0.8835\n",
            "Epoch 98/150\n",
            "8000/8000 [==============================] - 39s 5ms/step - loss: 0.2484 - acc: 0.9986 - val_loss: 0.9701 - val_acc: 0.8745\n",
            "Epoch 99/150\n",
            "4200/8000 [==============>...............] - ETA: 17s - loss: 0.2462 - acc: 0.9981"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-68ff9c281ca3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m972\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcvy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m          )\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxwQ2-uGChAj",
        "colab_type": "code",
        "outputId": "53bc2833-c06a-4ee6-b919-8e790669e8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "y_pred = model.predict(cvx.reshape(-1,972,40,1))\n",
        "matrix = confusion_matrix(cvy.argmax(axis=1), y_pred.argmax(axis=1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-63ce4b42008c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m972\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcvy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1167\u001b[0m                                             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m                                             steps=steps)\n\u001b[0m\u001b[1;32m   1170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m     def train_on_batch(self, x, y,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    292\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2669\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2670\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2621\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2622\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2623\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2624\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2625\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1469\u001b[0m     \"\"\"\n\u001b[1;32m   1470\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m           self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1425\u001b[0;31m               session._session, options_ptr, status)\n\u001b[0m\u001b[1;32m   1426\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uE621Q7w_0c",
        "colab_type": "code",
        "outputId": "c1e5b4b5-6508-4cbd-e001-c1c6394a1ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "matrix"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[337,  21,  10,  24,   8],\n",
              "       [ 17, 351,   6,   6,   3],\n",
              "       [ 15,  19, 288,  66,   9],\n",
              "       [ 22,  15,  34, 324,   6],\n",
              "       [ 16,   0,  13,  43, 347]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip1C1f2VS3AO",
        "colab_type": "code",
        "outputId": "539a240d-7e1f-45e7-9e6f-1ae129c507c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.unique(ty, return_counts=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4]), array([1600, 1617, 1603, 1599, 1581]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjj3eEuETlmY",
        "colab_type": "code",
        "outputId": "3bff3929-bc95-4db4-90f5-37bfb38781bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "np.unique(cvy, return_counts=True)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4]), array([400, 383, 397, 401, 419]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqIldBs6UVuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}